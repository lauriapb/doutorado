{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwvyK2XeDKP-",
    "outputId": "60db40e2-ed60-481b-9fad-229cb6e48028"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # se estiver no colab vai rodar o bloco abaixo\n",
    "    from google.colab import data_table, drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "    data_table.enable_dataframe_formatter()\n",
    "    data_table.DataTable.max_columns = 50\n",
    "    path = \"/content/drive/MyDrive/doutorado\"  # caminho do google drive\n",
    "except:\n",
    "    # se nao estiver no colab vai rodar o bloco abaixo\n",
    "    path = \".\"  # caminho local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sljJEpLcI_ur"
   },
   "outputs": [],
   "source": [
    "# carrega bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "b7S9sQWgKoC9",
    "outputId": "ca8d26dc-7e22-4ff6-e92b-d1f866d623fc"
   },
   "outputs": [],
   "source": [
    "# carrega dados do .csv\n",
    "dados = pd.read_csv(path + \"/dados_brasil_py.csv\", sep=\";\", index_col=0, parse_dates=True, na_values=[\"//\"], skipinitialspace=True, encoding=\"unicode_escape\")\n",
    "\n",
    "dados = dados.reset_index()  # reset index transforma \"timestamp\" em coluna comum, para fazer os cálculos de tempo\n",
    "dados.columns = dados.columns.str.strip()  # remove espaços em branco dos títulos das colunas\n",
    "dados = dados.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)  # remove espaços em branco do conteudo dos dados\n",
    "\n",
    "ix = dados.reset_index().index[dados[\"stroke_order\"] == \"a\"].tolist()  # procura o indice da linha em que \"stroke_order\" == \"a\"\n",
    "dados = [dados.iloc[a:b] for a, b in zip(ix, ix[1:] + [None])]  # cria uma lista com o subset das linhas entre o primeiro \"a\" e o proximo \"a\" (ultimo \"a\" não incluso)\n",
    "\n",
    "for r_idx, raio in enumerate(dados):\n",
    "    dados[r_idx][\"raio\"] = r_idx  # cria uma coluna \"raio\" com o numero do raio atual\n",
    "    dados[r_idx][\"nstroke\"] = range(1, len(raio) + 1)  # cria uma coluna \"nstroke\" com o numero do stroke\n",
    "    dados[r_idx][\"n_strokes\"] = len(raio)  # cria (atualiza) a coluna \"n_strokes\" com o numero total de strokes\n",
    "\n",
    "dados = pd.concat(dados)  # recria o dataframe com todos os raios e as novas colunas\n",
    "\n",
    "print(\"Total de descargas:\", len(dados))\n",
    "\n",
    "dados.head()  # mostra as primeiras linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkPjwjjSkIVB"
   },
   "outputs": [],
   "source": [
    "descargas = dados.copy()  # copia os \"dados\" em \"descargas\"\n",
    "\n",
    "descargas['subseq'] = \"\"  # Acrescenta a coluna 'subseq'\n",
    "descargas['after'] = \"\"  # Acrescenta a coluna 'after'\n",
    "descargas['where'] = \"\"  # Acrescenta a coluna 'where'\n",
    "descargas['raio_duracao'] = \"\"  # Acrescenta a coluna 'raio_duracao'\n",
    "\n",
    "# Aplica filtros de local, distancia, polaridade, etc\n",
    "# descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"local\"].isin([\"Utah\"]).any()) # selecionando locais\n",
    "descargas = descargas.groupby(\"raio\").filter(lambda r: ~r[\"local\"].isin([\"Utah\"]).any())  # excluindo Utah\n",
    "# descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"year\"].between(2003, 2011).any()) #seleciona o período\n",
    "# descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"dist1\"].between(0, 30, inclusive=\"right\").any()) #seleciona distancia\n",
    "descargas = descargas.groupby(\"raio\").filter(lambda r: not r[\"visib\"].isin([\"m\", \"f\"]).any())  # exclui as visibilidades\n",
    "descargas = descargas.groupby(\"raio\").filter(lambda r: not r[\"contact\"].isin(['0']).any())  # exclui ponto de contato igual a zero\n",
    "descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"Ip1\"].lt(0).any() and not r[\"Ip1\"].gt(0).any())  # negativos\n",
    "# descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"Ip1\"].gt(0).any() and not r[\"Ip1\"].lt(0).any()) # positivos\n",
    "# descargas = descargas.groupby(\"raio\").filter(lambda r: r[\"Ip1\"].lt(0).any() and r[\"Ip1\"].gt(0).any()) # bipolares\n",
    "\n",
    "descargas[\"CC_duration\"] = descargas[\"CC_duration\"].replace(0.0, np.nan)\n",
    "\n",
    "# intervalo entre descargas\n",
    "descargas[\"stroke_intv\"] = descargas[\"timestamp\"] - descargas[\"timestamp\"].shift()  # timestamp atual menos o timestamp anterior\n",
    "descargas[\"stroke_intv\"] = descargas[\"stroke_intv\"].dt.total_seconds() * 1000  # converte para ms\n",
    "descargas.loc[descargas[\"nstroke\"] == 1, \"stroke_intv\"] = np.nan  # onde nstroke == 1, invalida o valor de stroke_intv\n",
    "\n",
    "# ausencia de cc entre descargas\n",
    "descargas[\"no_cc\"] = (descargas[\"sec.ms\"] - (descargas[\"sec.ms\"] + descargas['CC_duration']/1000).shift())*1000\n",
    "descargas[\"no_cc\"] = descargas[\"no_cc\"].round(0).fillna(0.0).astype(int)\n",
    "descargas.loc[descargas[\"nstroke\"] == 1, \"no_cc\"] = np.nan  # onde nstroke == 1, invalida o valor de stroke_intv\n",
    "\n",
    "# variáveis para cálculo de parâmetros do stroke_intv\n",
    "stroke_intv_a = (descargas[descargas[\"CC_duration\"].between(0, 10)][\"stroke_intv\"])\n",
    "stroke_intv_b = (descargas[descargas[\"CC_duration\"].between(10, 40)][\"stroke_intv\"])\n",
    "stroke_intv_c = (descargas[descargas[\"CC_duration\"] > 40][\"stroke_intv\"])\n",
    "\n",
    "# limitando os valores do stroke_intv\n",
    "# stroke_intv_a = (descargas[descargas[\"CC_duration\"].between(0 , 10)][\"stroke_intv\"].between(0, 100)).mean()\n",
    "# stroke_intv_b = (descargas[descargas[\"CC_duration\"].between(10 , 40)][\"stroke_intv\"].between(0, 100)).mean()\n",
    "# stroke_intv_c = (descargas[descargas[\"CC_duration\"] > 40][\"stroke_intv\"].between(0, 100)).mean()\n",
    "\n",
    "# #Salva o arquivo 'descargas'\n",
    "# descargas.to_csv(\"descargas_nocc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNDuQdP7ck3O",
    "outputId": "97ec8448-c5a2-4386-ef57-37761cc0ccdd"
   },
   "outputs": [],
   "source": [
    "raios = descargas.groupby(\"raio\")  # agrupa por raio para calcular as estatisticas e outros parâmetros\n",
    "\n",
    "raios_min = raios.min(numeric_only=True)  # valores minimos\n",
    "raios_max = raios.max(numeric_only=True)  # valores maximos\n",
    "raios_sum = raios.sum(numeric_only=True)  # soma dos valores\n",
    "raios_first = raios.nth(0)  # primeiro stroke\n",
    "raios_last = raios.nth(-1)  # ultimo stroke\n",
    "raios_count = raios.count()  # total elementos no grupo\n",
    "raios_mean = raios.mean(numeric_only=True)\n",
    "raios_med = raios.median(numeric_only=True)\n",
    "\n",
    "raios_sum[\"n_strokes\"] = raios_last[\"n_strokes\"]  # reset no n_strokes da soma\n",
    "\n",
    "raios_cc = raios.filter(lambda r: r[\"CC_duration\"].ge(3).any())\n",
    "raios_cc = raios_cc.groupby([\"raio\"])\n",
    "\n",
    "raios_ccl = raios.filter(lambda r: r[\"CC_duration\"].gt(40).any())\n",
    "raios_ccl = raios_ccl.groupby([\"raio\"])\n",
    "\n",
    "raios_ccl_last = raios.filter(lambda r: r[\"CC_duration\"].iloc[-1] > 40)\n",
    "raios_ccl_last = raios_ccl_last.groupby([\"raio\"])\n",
    "\n",
    "# abaixo, raio_duracao = inicio_ultimo_stroke + duracao_ultimo_stroke - inicio_primeiro_stroke\n",
    "# raio_duracao = raios.nth(-1)[\"timestamp\"] + pd.to_timedelta(raios.nth(-1)[\"CC_duration\"], unit='ms') - raios.nth(0)[\"timestamp\"]\n",
    "\n",
    "descargas_cc = descargas[descargas[\"CC_duration\"].gt(2)]\n",
    "descargas_cc_muito_curta = descargas[descargas[\"CC_duration\"].between(3, 10, inclusive=\"both\")]\n",
    "descargas_cc_curta = descargas[descargas[\"CC_duration\"].between(10, 40, inclusive=\"right\")]\n",
    "descargas_cc_longa = descargas[descargas[\"CC_duration\"].gt(40)]\n",
    "\n",
    "print(\"Raios:\", raios.ngroups)\n",
    "print(\"Raios CCL:\", raios_ccl.ngroups)\n",
    "print(\"Raios CC:\", raios_cc.ngroups)\n",
    "print(\"Raios CCL Last:\", raios_ccl_last.ngroups)\n",
    "print(\"Descargas:\", raios.size().sum())\n",
    "print(\"Descargas CC:\", len(descargas_cc))\n",
    "print(\"Descargas CC muito curta:\", len(descargas_cc_muito_curta))\n",
    "print(\"Descargas CC curta:\", len(descargas_cc_curta))\n",
    "print(\"Descargas CC longa:\", len(descargas_cc_longa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADMfWL6r2Kas"
   },
   "outputs": [],
   "source": [
    "contact = [raio for _, raio in raios]  # converte o groupby de df em uma lista de df\n",
    "\n",
    "# loop em cada raio (grupo de strokes)\n",
    "for r_idx, raio in enumerate(contact):\n",
    "    # abaixo, raio_duracao = inicio_ultimo_stroke + duracao_ultimo_stroke - inicio_primeiro_stroke\n",
    "    raio_duracao = raio.iloc[-1][\"timestamp\"] + pd.to_timedelta(raio.iloc[-1][\"CC_duration\"], unit='ms') - raio.iloc[0][\"timestamp\"]\n",
    "    d_idx = contact[r_idx].index[0]\n",
    "    descargas.at[d_idx, 'raio_duracao'] = round(raio_duracao.total_seconds() * 1000)\n",
    "\n",
    "    if len(raio) < 2:  # Para 'n_strokes' maior ou igual a 2. Se 'nstroke' = 1, não preencha nada.\n",
    "        continue\n",
    "\n",
    "    raio.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Preencha 'subseq' da seguinte forma:\n",
    "    for s_idx, stroke in raio.iterrows():  # loop em cada stroke do raio para preencher o subseq\n",
    "        if s_idx == 0:  # se for o primeiro stroke, não faz nada\n",
    "            continue\n",
    "\n",
    "        # Observe, dentro do mesmo raio, a linha abaixo\n",
    "        s_curr = contact[r_idx].iloc[s_idx][\"contact\"]  # stroke atual\n",
    "        s_prev = contact[r_idx].iloc[s_idx - 1][\"contact\"]  # stroke anterior\n",
    "        if s_curr == s_prev:\n",
    "            # se o número for igual ao anterior, então imprima na coluna 'subseq' a palavra 'same'.\n",
    "            contact[r_idx].at[s_idx, \"subseq\"] = \"same\"\n",
    "        else:\n",
    "            # se o número for diferente do anterior, então imprima em 'subseq' a palavra 'new'.\n",
    "            contact[r_idx].at[s_idx, \"subseq\"] = \"new\"\n",
    "\n",
    "    # Preencha 'after' da seguinte forma:\n",
    "    for s_idx, stroke in raio.iterrows():  # loop em cada stroke do raio para preencher o after\n",
    "        if stroke[\"CC_duration\"] <= 40:  # Apenas para 'CC_duration' maior que 40.\n",
    "            continue\n",
    "\n",
    "        if stroke[\"nstroke\"] == stroke[\"n_strokes\"]:\n",
    "            # Se 'nstroke' = 'n_strokes' imprima em 'after' o valor '0'.\n",
    "            contact[r_idx].at[s_idx, \"after\"] = 0\n",
    "        else:\n",
    "            # Se 'nstroke' for diferente de 'n_strokes', então:\n",
    "            # Observe a coluna 'subseq', se houver algo escrito, imprima '1' em 'after'\n",
    "            # obs: sempre terá algo em subseq, então, after = 1\n",
    "            contact[r_idx].at[s_idx, \"after\"] = 1\n",
    "\n",
    "    # Preencha 'where' da seguinte forma. Haverá no final not, new ou same.\n",
    "    for s_idx, stroke in raio.iterrows():  # loop em cada stroke do raio para preencher o where\n",
    "        if stroke[\"after\"] == 0:\n",
    "            # Se 'after' = '0', então imprima 'not'\n",
    "            contact[r_idx].at[s_idx, \"where\"] = \"not\"\n",
    "        elif stroke[\"after\"] == 1:\n",
    "            # Se 'after' = '1', então observe a linha imediatamente seguinte em 'subseq',\n",
    "            if contact[r_idx].iloc[s_idx + 1][\"subseq\"] == \"same\":\n",
    "               # se for 'same', imprima em 'where' a palavra 'same'\n",
    "                contact[r_idx].at[s_idx, \"where\"] = \"same\"\n",
    "            else:\n",
    "                # se a linha seguinte for 'new', imprima em 'after' a palavra 'new'.\n",
    "                contact[r_idx].at[s_idx, \"where\"] = \"new\"\n",
    "\n",
    "contact = pd.concat(contact)  # converte de volta a lista de df para um df completo\n",
    "\n",
    "contact.to_csv(\"nocc_contact.csv\", index=False)  # Salva o arquivo 'contact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikF-RSk0Fg5N"
   },
   "outputs": [],
   "source": [
    "nocc_contact = descargas  # copia as descargas\n",
    "nocc_contact = nocc_contact.groupby(\"raio\").filter(lambda r: r[\"n_strokes\"].gt(1).all())  # filtra\n",
    "nocc_contact = nocc_contact.groupby(\"raio\").filter(lambda r: r[\"contact\"].eq(\"1\").all())  # filtra\n",
    "nocc_contact\n",
    "nocc_contact.to_csv(\"nocc_contact.csv\", index=False)  # Salva o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXpDyIW0morI"
   },
   "outputs": [],
   "source": [
    "# acrescenta no conjunto de dados as colunas cc_total e cc_max com os valores correspondentes\n",
    "descargas['cc_total'] = raios_sum[\"CC_duration\"]\n",
    "descargas['cc_max'] = raios_max[\"CC_duration\"]\n",
    "descargas.to_csv(\"nocc_contact.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
